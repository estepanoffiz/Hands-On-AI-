{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "094de6cc-e413-446f-8f30-84f5cdaba80c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Name | Matr.Nr. | Due Date\n",
    ":--- | ---: | ---:\n",
    "Sergey Stepaanov | 12140199 | 30.03.2023, 08:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39209693-5eff-4c74-a986-0c4d38c39cb5",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Hands-on AI II</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\">Unit 2 &ndash; The Vanishing Gradient Problem (Assignment)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-agency",
   "metadata": {},
   "source": [
    "<b>Authors:</b> B. Schäfl, S. Lehner, J. Brandstetter, A. Schörgenhumer<br>\n",
    "<b>Date:</b> 21-03-2023\n",
    "\n",
    "This file is part of the \"Hands-on AI II\" lecture material. The following copyright statement applies to all code within this file.\n",
    "\n",
    "<b>Copyright statement:</b><br>\n",
    "This material, no matter whether in printed or electronic form, may be used for personal and non-commercial educational use only. Any reproduction of this material, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-visiting",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">How to use this notebook</h3>\n",
    "\n",
    "This notebook is designed to run from start to finish. There are different tasks (displayed in <span style=\"color:rgb(248,138,36)\">orange boxes</span>) which require your contribution (in form of code, plain text, ...). Most/All of the supplied functions are imported from the file <code>u2_utils.py</code> which can be seen and treated as a black box. However, for further understanding, you can look at the implementations of the helper functions. In order to run this notebook, the packages which are imported at the beginning of <code>u2_utils.py</code> need to be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37206b-97b9-42f8-90d3-de8904215c97",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Important:</b> Set the random seed with <code>u2.set_seed(17)</code> to enable reproducible results in all tasks that incorporate randomness (e.g., t-SNE, splitting data intro train and test sets, initializing weights of a neural network, running the model optimization with random batches, etc.). You must use <code>17</code> as seed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bearing-houston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed Python version: 3.9 (✓)\n",
      "Installed numpy version: 1.22.3 (✓)\n",
      "Installed pandas version: 1.4.1 (✓)\n",
      "Installed PyTorch version: 1.10.2 (✓)\n",
      "Installed scikit-learn version: 1.2.2 (✓)\n",
      "Installed matplotlib version: 3.6.1 (✓)\n",
      "Installed seaborn version: 0.11.2 (✓)\n"
     ]
    }
   ],
   "source": [
    "# Import pre-defined utilities specific to this notebook.\n",
    "import u2_utils as u2\n",
    "\n",
    "# Import additional utilities needed in this notebook.\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import sklearn\n",
    "\n",
    "from typing import Dict, Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set default plotting style.\n",
    "sns.set()\n",
    "\n",
    "# Setup Jupyter notebook (warning: this may affect all Jupyter notebooks running on the same Jupyter server).\n",
    "u2.setup_jupyter()\n",
    "\n",
    "# Check minimum versions.\n",
    "u2.check_module_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-receipt",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Definition of Auxiliaries</h2>\n",
    "\n",
    "In this exercise, you will be working with a data set composed of images of various handwritten digits. It is probably <i>the</i> most prominent data set in the domain of machine learning: the <i>MNIST</i> data set. The data set distinguishes <i>ten</i> different classes, one for each digit (<i>zero</i> to <i>nine</i>). For curious minds, more information regarding this data set can be found at:\n",
    "\n",
    "<center>\n",
    "    <cite>LeCun, Y., 1998. The MNIST database of handwritten digits. <a href=\"http://yann.lecun.com/exdb/mnist/\">http://yann.lecun.com/exdb/mnist/</a>.</cite>\n",
    "</center><br>\n",
    "    \n",
    "Before analyzing and tackling the vanishing gradient problem, the data sets needs to be inspected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-timeline",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 1.1. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Load the <i>MNIST</i> data set using the appropriate function as supplied by us.</li>\n",
    "        <li>Split the data set into a training set and a test set in a ratio of $4:1$.</li>\n",
    "        <li>Visualize the MNIST training set in tabular form.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "metropolitan-microwave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62037</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57262</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39815</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44029</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48579</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23937</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25670</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12041</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "62037     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "57262     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "39815     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5338      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "44029     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "48579     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "23937     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "25670     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1428      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "12041     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "62037      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "57262      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "39815      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "5338       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "44029      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "48579      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "23937      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "25670      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1428       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "12041      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  pixel784  digit  \n",
       "62037       0.0       0.0       0.0       0.0      5  \n",
       "57262       0.0       0.0       0.0       0.0      2  \n",
       "39815       0.0       0.0       0.0       0.0      6  \n",
       "5338        0.0       0.0       0.0       0.0      8  \n",
       "44029       0.0       0.0       0.0       0.0      0  \n",
       "...         ...       ...       ...       ...    ...  \n",
       "48579       0.0       0.0       0.0       0.0      3  \n",
       "23937       0.0       0.0       0.0       0.0      6  \n",
       "25670       0.0       0.0       0.0       0.0      4  \n",
       "1428        0.0       0.0       0.0       0.0      3  \n",
       "12041       0.0       0.0       0.0       0.0      1  \n",
       "\n",
       "[56000 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mnist = u2.load_mnist()\n",
    "data_mnist_train, data_mnist_test = u2.split_data(data_mnist, test_size=1.0 / 5.0)\n",
    "data_mnist_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc11946-0e84-4cb5-a36b-54aefb4bc5f3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 1.2. [3 Points]</b><br>\n",
    "    Answer the following questions:\n",
    "    <ul>\n",
    "        <li>How many samples does the data set contain?</li>\n",
    "        <li>How many samples does the training and the test set contain?</li>\n",
    "        <li>How many features does the data set consist of (not counting the class label column <i>digit</i>)?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a137c8e-a1fa-4415-aa27-996d641134cc",
   "metadata": {},
   "source": [
    "Samples:70000\n",
    "Samples(Training and Test):70000\n",
    "Features:784"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-measurement",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 1.3. [6 Points]</b>\n",
    "    <ul>\n",
    "        <li>Reduce the dimensionality of the MNIST training set using <i>t-SNE</i>. To avoid long computation times, select a subset of the training data with $n=3000$ samples, and then perform <i>PCA</i> with $40$ components first. Afterwards, apply t-SNE with $2$ components on this PCA data (choose the perplexity yourself).</li>\n",
    "        <li>Visualize the t-SNE downprojection.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fleet-crime",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jg/_3b4_w392bv1y2c4ck4mmdsr0000gn/T/ipykernel_39080/2756557944.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmnist_train_subset_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_train_subset_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_train_subset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'digit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_train_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'digit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_mnist_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_train_subset_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata_mnist_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_tsne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_mnist_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mu2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_points_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_mnist_tsne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_train_subset_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/AI/SS23/Hands-On-AI-/Assignment 2/u2_utils.py\u001b[0m in \u001b[0;36mapply_tsne\u001b[0;34m(n_components, data, target_column, perplexity)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mprojected_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         projected_data = pd.DataFrame(TSNE(n_components=n_components, perplexity=float(perplexity), learning_rate=200,\n\u001b[0m\u001b[1;32m    191\u001b[0m                                            init=\"random\").fit_transform(data), index=data.index)\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprojected_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mdistances_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"distance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors_graph\u001b[0;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"distance\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m             \u001b[0mA_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m             \u001b[0mA_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    822\u001b[0m         )\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             results = ArgKmin.compute(\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             return ArgKmin32.compute(\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36mthreadpool_limits\u001b[0;34m(limits, user_api)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreadpool_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, limits, user_api)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_threadpool_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_set_threadpool_limits\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         modules = _ThreadpoolInfo(prefixes=self._prefixes,\n\u001b[0m\u001b[1;32m    269\u001b[0m                                   user_api=self._user_api)\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_if_incompatible_openmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_load_modules\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;34m\"\"\"Loop through loaded libraries and store supported ones\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"darwin\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_modules_with_dyld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"win32\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_find_modules_with_dyld\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Store the module if it is supported and selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_module_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_make_module_from_path\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefixes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0muser_api\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0mmodule_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_RTLD_NOLOAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_extra_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36mget_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    644\u001b[0m                              lambda: None)\n\u001b[1;32m    645\u001b[0m         \u001b[0mget_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"OpenBLAS\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "mnist_train_subset = data_mnist_train.sample(3000)\n",
    "mnist_train_subset_X, mnist_train_subset_Y = mnist_train_subset.drop(columns='digit'), mnist_train_subset['digit']\n",
    "data_mnist_pca = u2.apply_pca(n_components=40, data=mnist_train_subset_X)\n",
    "data_mnist_tsne = u2.apply_tsne(n_components=2, data=data_mnist_pca, perplexity=30)\n",
    "u2.plot_points_2d(data=data_mnist_tsne, targets=mnist_train_subset_X, figsize=(14, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c0c55-4671-4ad4-bc4a-1f06a870c29a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 1.4. [2 Points]</b>\n",
    "    <ul>\n",
    "        <li>Comment on the separability of the MNIST training (sub)set with respect to the downprojection.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc695e84-c897-4724-901c-abc1291ddcf0",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4817c2d-bf6c-458c-8a63-6715a7cbab2d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 1.5. [2 Points]</b>\n",
    "    <ul>\n",
    "        <li>Given the results above, do you think that there is some model that can classify the data set (decently) well? State your reasoning.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d522603-d78d-40bc-8024-e7775bb0569d",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-glasgow",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Training of a Neural Network</h2>\n",
    "\n",
    "Loading and inspecting a new data set is always an exciting moment, but even more exciting is the implementation of a corresponding neural network and applying it to said data set. In this section, you will thus have to implement and train an appropriate neural network model and revisit your knowledge about the <i>forward</i> as well as the <i>backward</i> pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51af548-d5ef-4ce0-8e1a-88b303cb7eab",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Important:</b> The following code snippet is taken from the accompanying exercise notebook. Do not modify this code here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f358437-2e6d-4e6b-af5b-1c7545473c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model: torch.nn.Module, optimizer: torch.optim.Optimizer, num_epochs: int,\n",
    "                       loader_train: torch.utils.data.DataLoader, loader_test: torch.utils.data.DataLoader,\n",
    "                       device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')) -> None:\n",
    "    \"\"\"\n",
    "    Auxiliary function for training and evaluating a corresponding model.\n",
    "    \n",
    "    :param model: model instance to train and evaluate\n",
    "    :param optimizer: optimizer to use for model training\n",
    "    :param num_epochs: amount of epochs for model training\n",
    "    :param loader_train: data loader supplying the training samples\n",
    "    :param loader_test: data loader supplying the test samples\n",
    "    :param device: device to use for model training and evaluation\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train model instance for one epoch.\n",
    "        u2.train_network(\n",
    "            model=model,\n",
    "            data_loader=loader_train,\n",
    "            device=device,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "\n",
    "        # Evaluate current model instance.\n",
    "        performance = u2.test_network(\n",
    "            model=model,\n",
    "            data_loader=loader_train,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Print result of current epoch to standard out.\n",
    "        print(f'Epoch: {str(epoch + 1).zfill(len(str(num_epochs)))} ' +\n",
    "              f'/ Train loss: {performance[0]:.4f} / Train accuracy: {performance[1]:.4f}')\n",
    "\n",
    "    # Evaluate final model on test data set.\n",
    "    performance = u2.test_network(model=model, data_loader=loader_test, device=device)\n",
    "    print(f'\\nTest loss: {performance[0]:.4f} / Test accuracy: {performance[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d5d31b-5856-4a6d-a40b-6ac88f2c1b95",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 2.1. [4 Points]</b>\n",
    "    <ul>\n",
    "        <li>Create a corresponding <code>TensorDataset</code> for the training as well as the test set.</li>\n",
    "        <li>Wrap the previously defined <code>TensorDataset</code> instances in separate <code>DataLoader</code> instances with a batch size of $80$ (shuffle the training data set).</li>\n",
    "        <li>Scale the features of the training as well as test set by a factor of $\\frac{1}{255}$, i.e., normalize the data to range $[0; 1]$</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51c13174-dbe2-480c-be7b-8306557e4fa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_mnist_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jg/_3b4_w392bv1y2c4ck4mmdsr0000gn/T/ipykernel_39080/2503614050.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m loader_mnist_train = torch.utils.data.DataLoader(\n\u001b[1;32m      3\u001b[0m     dataset=torch.utils.data.TensorDataset(\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_mnist_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# normalize to range [0; 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_mnist_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_mnist_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Create data loader for iterating the Fashion-MNIST training data set.\n",
    "loader_mnist_train = torch.utils.data.DataLoader(\n",
    "    dataset=torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(data_mnist_train.drop(columns=['item_type']).values / 255),  # normalize to range [0; 1]\n",
    "        torch.from_numpy(data_mnist_train['item_type'].values)\n",
    "    ),\n",
    "    batch_size=80,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create data loader for iterating the Fashion-MNIST test data set.\n",
    "loader_mnist_test = torch.utils.data.DataLoader(\n",
    "    dataset=torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(data_mnist_train.drop(columns=['item_type']).values / 255),  # normalize to range [0; 1]\n",
    "        torch.from_numpy(data_mnist_train['item_type'].values)\n",
    "    ),\n",
    "    batch_size=80,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-smart",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 2.2. [6 Points]</b>\n",
    "    <ul>\n",
    "        <li>Implement a class <code>FNN_0</code> with the following architecture (square weight matrix means that the input size is equal to the output size):</li>\n",
    "    </ul>\n",
    "    <table style=\"text-align:center;vertical-align:middle\">\n",
    "        <th>Position</th>\n",
    "        <th>Element</th>\n",
    "        <th>Comment</th>\n",
    "        <tr>\n",
    "            <td>0</td>\n",
    "            <td>input</td>\n",
    "            <td>input size = $28\\times{}28 = 784$</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>1</td>\n",
    "            <td>fully connected</td>\n",
    "            <td>$512$ output features</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>2</td>\n",
    "            <td>sigmoid</td>\n",
    "            <td>-</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>3</td>\n",
    "            <td>fully connected</td>\n",
    "            <td>square weight matrix</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>4</td>\n",
    "            <td>sigmoid</td>\n",
    "            <td>-</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>5</td>\n",
    "            <td>fully connected</td>\n",
    "            <td>square weight matrix</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>6</td>\n",
    "            <td>sigmoid</td>\n",
    "            <td>-</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>7</td>\n",
    "            <td>fully connected</td>\n",
    "            <td>square weight matrix</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>8</td>\n",
    "            <td>sigmoid</td>\n",
    "            <td>-</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>9</td>\n",
    "            <td>fully connected</td>\n",
    "            <td>square weight matrix</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>10</td>\n",
    "            <td>sigmoid</td>\n",
    "            <td>-</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>11</td>\n",
    "            <td>fully connected</td>\n",
    "            <td>$10$ output features</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN_0(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 512)\n",
    "        self.ac1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(512, 512)\n",
    "        self.ac2 = torch.nn.Sigmoid()\n",
    "        self.fc3 = torch.nn.Linear(512, 512)\n",
    "        self.ac3 = torch.nn.Sigmoid()\n",
    "        self.fc4 = torch.nn.Linear(512, 512)\n",
    "        self.ac4 = torch.nn.Sigmoid()\n",
    "        self.fc5 = torch.nn.Linear(512, 512)\n",
    "        self.ac5 = torch.nn.Sigmoid()\n",
    "        self.fc6 = torch.nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ac3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.ac4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.ac5(x)\n",
    "        return self.fc6(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41791eeb-7731-4253-b9f7-edd6f72619a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 2.3. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Create an instance of <code>FNN_0</code> as well as of a corresponding <code>SGD</code> optimizer with a learning rate of $0.05$.</li>\n",
    "        <li>Print the resulting model and verify the architecture by inspecting the output.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LogisticRegression instance and the corresponding optimizer to use.\n",
    "fnn_0 = FNN_0()\n",
    "optimizer = torch.optim.SGD(fnn_0.parameters(), lr=0.05)\n",
    "\n",
    "# Show the architecture of the logistic regression model.\n",
    "print(fnn_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e6bcb-641d-4d85-8f3a-6d1f367b12a6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 2.4. [2 Points]</b>\n",
    "    <ul>\n",
    "        <li>Train an <code>FNN_0</code> network for $6$ epochs, print the training accuracy as well as the loss per epoch and report the final test set loss and accuracy.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(\n",
    "    model=fnn_0,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=6,\n",
    "    loader_train=loader_fashion_mnist_train,\n",
    "    loader_test=loader_fashion_mnist_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613768f-ff64-4758-8f77-f4c6f7e8664d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 2.5. [2 Points]</b>\n",
    "    <ul>\n",
    "        <li>What do you observe?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ac4e9-8f50-4da9-b6fe-e85ec84bdd82",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-accuracy",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 2.6. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Write down a formula for the corresponding <i>forward</i> pass of <code>FNN_0</code>. Use the same notation as presented during the exercise.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-florence",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \\begin{equation}\n",
    "        \\hat{y} = g\\left(h^{(5)}(h^{(4)}(h^{(3)}(h^{(2)}(h^{(1)}(\\mathbf{x};\\mathbf{W}_1);\\mathbf{W}_2);\\mathbf{W}_3);\\mathbf{W}_4;\\mathbf{W}_5;\\mathbf{W}_6 \\right )\n",
    "    \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-guyana",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 2.7. [4 Points]</b>\n",
    "    <ul>\n",
    "        <li>Write down a formula for the corresponding <i>backward</i> pass of <code>FNN_0</code>. Use the same notation as presented during the exercise.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-calvin",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \\begin{align*}\n",
    "        \\mathbf{W}_6 & \\leftarrow \\mathbf{W}_6 - \\eta \\frac{\\partial L}{\\partial \\mathbf{W}_6} \\\\\n",
    "        \\mathbf{W}_5 & \\leftarrow \\mathbf{W}_5 - \\eta \\frac{\\partial L}{\\partial h^{(5)}}\\frac{\\partial h^{(5)}}{\\partial \\mathbf{W}_5} \\\\\n",
    "        \\mathbf{W}_4 & \\leftarrow \\mathbf{W}_4 - \\eta \\frac{\\partial L}{\\partial h^{(5)}}\\frac{\\partial h^{(5)}}{\\partial h^{(4)}}\\frac{\\partial h^{(4)}}{\\partial \\mathbf{W}_4} \\\\\n",
    "        \\mathbf{W}_3 & \\leftarrow \\mathbf{W}_3 - \\eta \\frac{\\partial L}{\\partial h^{(5)}}\\frac{\\partial h^{(5)}}{\\partial h^{(4)}}\\frac{\\partial h^{(4)}}{\\partial h^{(3)}}\\frac{\\partial h^{(3)}}{\\partial \\mathbf{W}_3} \\\\\n",
    "        \\mathbf{W}_2 & \\leftarrow \\mathbf{W}_2 - \\eta \\frac{\\partial L}{\\partial h^{(5)}}\\frac{\\partial h^{(5)}}{\\partial h^{(4)}}\\frac{\\partial h^{(4)}}{\\partial h^{(3)}}\\frac{\\partial h^{(3)}}{\\partial h^{(2)}}\\frac{\\partial h^{(2)}}{\\partial \\mathbf{W}_2} \\\\\n",
    "         \\mathbf{W}_1 & \\leftarrow \\mathbf{W}_1 - \\eta \\frac{\\partial L}{\\partial h^{(5)}}\\frac{\\partial h^{(5)}}{\\partial h^{(4)}}\\frac{\\partial h^{(4)}}{\\partial h^{(3)}}\\frac{\\partial h^{(3)}}{\\partial h^{(2)}}\\frac{\\partial h^{(2)}}{\\partial h^{(1)}}\\frac{\\partial h^{(1)}}{\\partial \\mathbf{W}_1} \\\\\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-organization",
   "metadata": {},
   "source": [
    "<h2>Analyzing Gradients</h2>\n",
    "\n",
    "Is the performance problem of <code>FNN_0</code> related to the vanishing gradient problem? This is exactly the point you're going to figure out in this exercise. As a first step, the gradients of a freshly initialized model need to be collected and analyzed. Afterwards, in case of a vanishing gradient problem, countermeasures must be taken.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-hammer",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Important:</b> The following code snippet is taken from the accompanying exercise notebook. Do not modify this code here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_gradients(model: torch.nn.Module, loader: torch.utils.data.DataLoader,\n",
    "                      device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')) -> Sequence[Dict[str, np.array]]:\n",
    "    \"\"\"\n",
    "    Auxiliary function for collecting gradients of a corresponding model.\n",
    "    \n",
    "    :param model: model instance to be used for collecting gradients\n",
    "    :param loader: data loader supplying the samples used for collecting gradients\n",
    "    :param device: device to use for gradient collection\n",
    "    :return: sequence of parameter names and gradients, averaged over all parameter elements\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model_state = model.training\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Iterating over the data set and computing the corresponding gradients.\n",
    "    # Since we are only interested in the gradients, we can skip the optimization step.\n",
    "    gradients = {}\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for data, target in loader:\n",
    "        data, target = data.float().to(device), target.long().to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Collecting the (averaged absolute) gradients from the current model.\n",
    "        for name, parameter in model.named_parameters():\n",
    "            if \"weight\" in name and parameter.grad is not None:\n",
    "                gradients.setdefault(name, []).append(parameter.grad.view(-1).abs().mean().item())\n",
    "        model.zero_grad()\n",
    "    \n",
    "    # Reset model state and return collected gradients.\n",
    "    model.train(mode=model_state)\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-study",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3.1. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Create a <i>fresh</i> instance of <code>FNN_0</code> and collect its gradients using the MNIST training set.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for model_class in [FNN_0]:\n",
    "    # Set random seed for reproducibility.\n",
    "    u2.set_seed(0)\n",
    "    \n",
    "    # Create logistic regression models.\n",
    "    models.append(model_class())\n",
    "    \n",
    "gradients = [(model, collect_gradients(model=model, loader=loader_fashion_mnist_train)) for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74175026-869a-4839-be0d-f3a4cfb4b607",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3.2. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Visualize the gradients of each weight parameter accordingly.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_dfs = []\n",
    "for model, gradient in gradients:\n",
    "    gradient_data = pd.DataFrame(gradient)\n",
    "    gradient_data.columns = [f\"Layer {i + 1}\" for i in range(len(gradient))]\n",
    "    gradient_data = pd.melt(gradient_data, var_name=\"Layer\", value_name=\"Gradient Magnitude\")\n",
    "    gradient_data[\"Model\"] = type(model).__name__\n",
    "    gradient_dfs.append(gradient_data)\n",
    "\n",
    "# Combine all gradients in a single data frame.\n",
    "gradients_df = pd.concat(gradient_dfs)\n",
    "\n",
    "# Define plotting figure and corresponding attributes.\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.set(yscale='log')\n",
    "\n",
    "# Plot pre-processed gradients.\n",
    "sns.boxplot(x='Model', y='Gradient Magnitude', hue='Layer', data=gradients_df, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b839caf-0d92-45bc-ad74-59cda763027e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3.3. [2 Points]</b>\n",
    "    <ul>\n",
    "        <li>What do you observe?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a7d99-8fb4-4772-91c3-594f7c33ca7c",
   "metadata": {},
   "source": [
    "Gradient Magnitude increasing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-wesley",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3.4. [6 Points]</b>\n",
    "    <ul>\n",
    "        <li>Assume a vanishing gradient. Apply the countermeasure presented during the accompanying exercise by implementing a corresponding <code>FNN_1</code> network.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN_1(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 512)\n",
    "        self.ac1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(512, 512)\n",
    "        self.ac2 = torch.nn.Sigmoid()\n",
    "        self.fc3 = torch.nn.Linear(512, 512)\n",
    "        self.ac3 = torch.nn.Sigmoid()\n",
    "        self.fc4 = torch.nn.Linear(512, 512)\n",
    "        self.ac4 = torch.nn.Sigmoid()\n",
    "        self.fc5 = torch.nn.Linear(512, 512)\n",
    "        self.ac5 = torch.nn.Sigmoid()\n",
    "        self.fc6 = torch.nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ac3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.ac4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.ac5(x)\n",
    "        return self.fc6(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9643e-a56f-4fae-ba12-546328ceecbf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3.5. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Create an instance of <code>FNN_1</code> as well as of a corresponding <code>SGD</code> optimizer with a learning rate of $0.05$.</li>\n",
    "        <li>Print the resulting model and verify the architecture by inspecting the output.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility.\n",
    "u2.set_seed(0)\n",
    "\n",
    "# Create FNN_1 network instance and the corresponding optimizer to use.\n",
    "fnn_1 = FNN_1()\n",
    "optimizer = torch.optim.SGD(fnn_1.parameters(), lr=0.05)\n",
    "\n",
    "# Show the architecture of the FNN_1 network model.\n",
    "print(fnn_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e3ab9-0ba6-4474-9182-f0766b6a773d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3.6. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Train an <code>FNN_1</code> network for $6$ epochs, print the training accuracy as well as the loss per epoch and report the final test set loss and accuracy.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(\n",
    "    model=fnn_1,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=6,\n",
    "    loader_train=loader_fashion_mnist_train,\n",
    "    loader_test=loader_fashion_mnist_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf4341-90d7-4017-a621-4c768f067cc0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3.7. [2 Points]</b>\n",
    "    <ul>\n",
    "        <li>What do you observe?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686fb3a7-7cee-4ff3-bbe4-aaa2ac5fb22b",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-struggle",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3.8. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Create a <i>fresh</i> instance of <code>FNN_1</code> and collect its gradients using the MNIST training set.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6317586-7efc-4245-b9e3-7db12a36e571",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3.9. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Visualize the gradients of each weight parameter accordingly. Include the gradient visualization of <code>FNN_0</code> to enable a direct comparison.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09eb7f-d8b4-443f-ac4c-2d24f812fcde",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3.10. [2 Points]</b>\n",
    "    <ul>\n",
    "        <li>What do you observe?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941c9ed-78b7-4d52-86d5-ebb84369610e",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-southeast",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Deriving Derivatives</h2>\n",
    "\n",
    "It is already known from the lecture as well as the exercise that <i>activation</i> functions are the primary culprit of the <i>Vanishing Gradient Problem</i>. Hence, it is important to know <i>how</i> the chosen activation functions activate the input and consequently what the <i>derivative</i> is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-singapore",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 4.1. [4 Points]</b><br>\n",
    "    Take a look at the official <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Hardsigmoid.html#torch.nn.Hardsigmoid\">PyTorch documentation</a> to solve the following tasks:\n",
    "    <ul>\n",
    "        <li>Implement the <code>hardsigmoid</code> activation function as it was done for <code>relu</code> in the exercise.</li>\n",
    "        <li>Implement the <i>derivative</i> of the <code>hardsigmoid</code> activation function accordingly.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardsigmoid(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the rectified linear unit function.\n",
    "    \n",
    "    :param x: the input on which to apply the rectified linear unit function\n",
    "    :return: the result of the rectified linear unit function applied to its input\n",
    "    \"\"\"\n",
    "    return max(0.0, x)\n",
    "\n",
    "\n",
    "def hardsigmoid_d(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the derivate of the rectified linear unit function.\n",
    "    \n",
    "    :param x: the input to the rectified linear unit function for computing its derivative\n",
    "    :return: the derivative of the rectified linear unit function with respect to its input\n",
    "    \"\"\"\n",
    "    return 0.0 if x <= 0.0 else 1.0\n",
    "\n",
    "\n",
    "# Crudly check the value range of the rectified linear unit function and its derivative.\n",
    "for x in [-10.0, 0.0, 10.0]:\n",
    "    print(f'hardsigmoid({x:>5}): {hardsigmoid(x):7.4f} | hardsigmoid\\'({x:>5}): {hardsigmoid_d(x):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd7520-f73c-43b1-9859-483193464590",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 4.2. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Find $5$ different inputs showing the <i>value range</i> of the <code>hardsigmoid</code> activation function as well as its derivative.</li>\n",
    "        <li>Plot the <code>hardsigmoid</code> activation function including its derivative for the input range $[-8; 8]$.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-clinic",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 4.3. [4 Points]</b><br>\n",
    "    Take a look at the official <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU\">PyTorch documentation</a> to solve the following tasks:\n",
    "    <ul>\n",
    "        <li>Implement the <code>leaky_relu</code> activation function as it was done for <code>relu</code> in the exercise. Use a <i>negative slope</i> of $0.25$.</li>\n",
    "        <li>Implement the <i>derivative</i> of the <code>leaky_relu</code> activation function accordingly.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bbfb82-f2bf-4243-9912-ddaf476d4489",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 4.4. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Find $5$ different inputs showing the <i>value range</i> of the <code>leaky_relu</code> activation function as well as its derivative.</li>\n",
    "        <li>Plot the <code>leaky_relu</code> activation function including its derivative for the input range $[-8; 8]$.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48feea-3251-4088-961a-a96e07edc956",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 4.5. [2 Points]</b>\n",
    "    <ul>\n",
    "        <li>Which of these two activation functions from above do you think is susceptible to the vanishing gradient problem? Explain your decision.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c82f63-5580-43e6-9dfa-0d63c83c9316",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9b0e0-7e3f-4f62-a79f-a67575576e78",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 4.6. [6 Points]</b>\n",
    "    <ul>\n",
    "        <li>Create the same network architecture as <code>FNN_0</code> but replace its activation function with the one you selected above in <b>Exercise 4.5.</b> (the one that is susceptible to the vanishing gradient problem). Name the new network <code>FNN_2</code>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e11fd-a974-427a-882a-c7fa45277c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60969550-ca50-487d-a593-19f5df79976f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 4.7. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Create a <i>fresh</i> instance of <code>FNN_2</code> and collect its gradients using the MNIST training set.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8bf34-d670-4e1c-9aa3-8bf380017c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54598fa9-962a-4aa4-bd1a-f896f6b9bc95",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 4.8. [3 Points]</b>\n",
    "    <ul>\n",
    "        <li>Visualize the gradients of each weight parameter accordingly. Include the gradient visualization of <code>FNN_0</code> to enable a direct comparison.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2be3b-1a81-44c9-ad87-e5bdc49be83c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e9c21-0cd0-4ed0-8032-cb785cb3804a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 4.9. [2 Points]</b>\n",
    "    <ul>\n",
    "        <li>What do you observe?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298606f9-62be-458f-9d7a-24b1e2dd60c3",
   "metadata": {},
   "source": [
    "your answer goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
